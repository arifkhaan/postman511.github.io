<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8" >
<meta http-equiv="X-UA-Compatible" content="chrome=1" >
<meta name="keywords" content="video coding,HEVC,H.264,H.265,rate control,codec,AVC,VVC, Miaohui Wang, 王妙辉, 妙辉">
<title>Miaohui Wang | Shenzhen University</title>
  
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
</head>

  
<body>
<tbody>
<tr>
<td style="display:none;width:150px"></td>
<h1 align="center" style="margin-right:48pt;text-indent:0.5in"><a href="https://charwill.github.io/">Miaohui Wang</a>&nbsp;<span style="font-size:12pt">Ph.D.&nbsp;</span><img height="50" src="https://sites.google.com/site/wangmiaohui/name.gif?attredirects=0" width="169"></h1>
<h3 align="left"><a name="TOC--"></a> </h3>
</tr>
</tbody>






<br />
<br />
<div style="display:inline;float:left;margin:5px 10px 0px 0px"><font face="arial, sans-serif" style="font-size:xx-large"><img border="0" height="200" src="https://sites.google.com/site/wangmiaohui/head_photo.png?attredirects=0" style="display:block;margin-right:auto;text-align:left" width="153"></font></div>


<br />
<br />
<div><font size="4"><b>Assistant Professor (tenure-track), Shenzhen University (SZU)</b></font></div>
<div><font size="4">Ph.D. (CUHK), IEEE Member</font></div>
<div><font size="4">Tel: +86-0755-2665-9561</font></div>
<div><font size="4">Email: wang.miaohui[#AT#]gmail[dot]com&nbsp;or&nbsp;mhwang[#AT#]link[dot]cuhk[dot]edu[dot]hk &nbsp;or&nbsp;mhwang[#AT#]szu[dot]edu[dot]cn</font></div>


<br />
<br />
<div style="text-align:justify"><font size="4">
Dr. <b>Miaohui Wang</b> (S'13-M'16) received the Ph.D. degree in 2015 under the supervision of Prof. <a href="http://www.ee.cuhk.edu.hk/~knngan/" rel="nofollow"><b>King Ngi Ngan</b></a> (IEEE Fellow, IET Fellow,  National Thousand Talents Program) from Department of Electronic Engineering, The <b><a href="http://www.ee.cuhk.edu.hk/en-gb/" rel="nofollow">Chinese University of Hong Kong </a></b>(CUHK), Hong Kong, P. R. China. From 2014 to 2015, he was a researcher working on the standardization of video coding in the Innovation Laboratory, <b><a href="https://www.interdigital.com/" rel="nofollow">InterDigital Inc.</a></b>, San Diego, CA, USA. From 2015 to 2017, He was a senior research staff working on computer vision and machine learning in <b><a href="http://tclrd.com.hk/" rel="nofollow">The Creative Life (TCL) Research Institute of Hong Kong</a></b>, Hong Kong, P. R. China. He joined <b><a href="https://en.wikipedia.org/wiki/Shenzhen_University" rel="nofollow">Shenzhen University </a></b>(SZU) as an assistant professor in 2017. He is currently with College of Information Engineering, SZU, Shenzhen, P. R. China.</font></div>



<br />
<br />
<div style="text-align:justify"> 
<font size="4">
Dr. Wang was the recipient of the Best Thesis Awards of <b><a href='http://www.shanghai.gov.cn/shanghai/node27118/node27386/node27400/node27838/userobject22ai38994.html'>Ministry of Education of Shanghai City</a></b> and <b><a href="http://www.fudan.edu.cn/en/" rel="nofollow">Fudan University</a></b>, respectively. He received the Best Paper Award in International Conference on Advanced Hybrid Information Processing (2018), and received the second runner-up of Grand Challenge on “Learning-Based Image Inpainting” in International Conference on Multimedia & Expo (2019). He has authored or co-authored over 30 technical papers in international journals and conferences. His current research interests cover a wide range of topics related with image/video compression, transmission and analysis, computer vision and machine learning. He is a member of the <b><a href="http://ieee-cas.org/" rel="nofollow">IEEE Circuits and Systems Society</a></b>.
</font>
</div>








<br />
<br />
<div style="text-align:justify">
<h3><a name="funding"><b>Projects (Host):</b></a></h3>
<font size="4">
<ul>
<li>National Natural Science Foundation of China (NSFC), No 61701310, 2018.01-2020.12, <b>280,000.00 RMB</b>.</li>
<li>Natural Science Foundation of Guangdong, 2019.10-2022.09, <b>100,000.00 RMB</b>.</li>
<li>Natural Science Foundation of Shenzhen, 2019.01-2021.12, <b>300,000.00 RMB</b>.</li>
<li>Overseas High-Caliber Personnel Fund, 2019.01-2021.12, <b>2,700,000.00 RMB</b>.</li>
<li>Natural Science Foundation of Shenzhen University, 2018.01-2021.12, <b>200,000.00 RMB</b>.</li>
</ul>
</font>
</div>



<br />
<br />
<div style="text-align:justify">
<h3><a name="Students"><b>Student supervision:</b></a></h3>

<font size="4">
<ul>
<li>Xueqin Liu (postgraduate student, since Sep. 2019),  Video processing.</li>
<li>Yijing Huang (postgraduate student, since Sep. 2019),  Computer vision.</li>
<li>Xiaoming Chen (postgraduate student, since Sep. 2018), Deep-learned representations for video processing.</li>
<li>Jialin Zhang (postgraduate student, since Sep. 2018),  Video processing.</li>
<li>Weiqian Chen (postgraduate student, since Sep. 2017),  Video processing.</li>
<li>Jiaxin Lin (postgraduate student, since Sep. 2017), Image/video quality assessment.</li>
<li>Ying Chen (FYP student, 2018-2019), Compressed video quality assessment (Joined <b><a href="https://www.sensetime.com/" rel="nofollow">SenseTime, Inc.</a></b>).</li>
<li>Qionglin Zheng (FYP student, 2018-2019), Video super-resolution (Joined <b><a href="https://www.sensetime.com/" rel="nofollow">SenseTime, Inc.</a></b>).</li>
<li>Xiaofeng Luo (FYP student, 2018-2019), Video super-resolution.</li>
<li>Yue Hu (FYP student, 2018-2019), Video saliency detection.</li>
<li>Min Wang (FYP student, 2017-2018), License plate recognition based on low-resolution images.</li>
<li>Fujian Li (FYP student, 2017-2018), Real-time face recognition with FaceNet.</li>
<li>Guoming Chen (FYP student, 2017-2018), Deep learning-based image retrieval.</li>
<li>Wenshuo Feng (FYP student, 2017-2018), Deep learning-based image artistic style transfer.</li>
<li>Huoli Li (FYP student, 2017-2018), Automatic coloring of black-and-white photographs.</li>
<li>Wujun Zeng (FYP student, 2017-2018), Image quality assessment method-based on visual attention.</li>
<li>Weihuang Wen (FYP student, 2017-2018), Artistic style conversion of digital images.</li>
<li>Zhenxin Liu (FYP student, 2017-2018), License plate recognition system.</li>
</ul>
</font>
</div>
<br />



<hr />
<h3><a name="News"><b><font size="5" color="#ff0000">News！！！！！！</font></b></a></h3>
<div style="text-align:justify">
<font size="4">
<ul>
<li> <font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font> I serve as a Section Chair in International Conference on Multimedia & Expo (<b>ICME</b>), 2019.</li>
<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font> I'm looking for <font color="#ff0000"><b> Postdoctoral Fellows</b></font> in computer vision, machine learning and visual signal processing.  <b><font color="#ff0000">Competitive salary！</font></b>
  Drop your CV！</li>
<br />
<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font> 组里高薪(税后30W+)聘[<b>博士后</b>]及[<b>专职研究人员</b>]若干名，请直接联系我!  </li>
<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font> 组里现招有潜力的数学·计算机·电子信息方向的高年级[<b>本科生</b>]以及攻读学历的硕士[<b>研究生</b>]若干名，请直接联系我!</li>
<li>我们跟腾讯[AI Lab，优图，音视频实验室]、华为2012媒体实验室、商汤SenseTime、旷视MEGVII、大疆DJI、阿里AI、百度爱奇艺、快手、抖音...等公司有深入合作！欢迎有志于以上一线互联网公司求职的[<b>本科生</b>]进组学习。</li>
<br />
<li><b>要求</b>：自控力强，编程能力强，对科研有热情，有明确的学业规划</li>
</ul>
</div>


<hr />
<h3><a name="Prof_act"><b><font size="5"> Professional Activities</font></b></a></h3>
<table border="0" cellpadding="5" cellspacing="0">
<tbody>
<tr>
<td>Memberships</td>
<td>
<div align="justify">
<ul>
<li> IET </li>
<li> IEEE </li>
<li> CCF </li>
</ul>
</div>
</td>
</tr>
<tr>
<td>Journal Reviewer</td>
<td>
<div align="justify">
<ul>
<li>   IEEE Transaction on industrial electronics</li>
<li>   IEEE Transactions on Image Processing</li>
<li>   IEEE Transactions on Circuits and Systems for Video Technology</li>
<li>   IEEE Transactions on Multimedia</li>
<li>   IEEE Transactions on Broadcasting</li>
<li>   IEEE Journal on Emerging and Selected Topics in Circuits and Systems</li>
<li>   IEEE Access </li>
<li>   IEEE Signal Processing Letters</li>
<li>   IEEE Communications Letters</li>
<li>   ACM Transactions on Multimedia Computing Communications and Applications</li>
<li>   Elsevier Signal  Processing</li>
<li>   Elsevier Signal  Processing: Image Communication</li>
<li>   Elsevier Journal of Visual Communication and Image Representation</li>
<li>   Elsevier Neurocomputing</li>
<li>   Springer Signal, Image and Video Processing</li>
<li>   IET Image Processing </li>
<li>   IET Electronics Letters </li>
</ul>
</div>
</td>
</tr>
<tr>
<td>Conference Reviewer</td>
<td>
<div align="justify">
<ul>
<li>  Data Compression Conference (DCC)</li>
<li>  IEEE Picture Coding Symposium (PCS)</li>
<li>  IEEE International Conference on Multimedia and Expo (ICME)</li>
<li>  IEEE International Symposium on Circuits and Systems (ISCAS)</li>
<li>  IEEE International Conference on Image Processing (ICIP)</li>
<li>  IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</li>
<li>  IEEE Visual Communications and Image Processing (VCIP) </li>
<li>  IEEE International Workshop on Multimedia Signal Processing (MMSP)</li>
</ul>
</div>
</td>
</tr>
</tbody>
</table>


<hr>
<h3><a name="publications"><b><font size="5">Publications (Year of 2019)&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;[<span style="background-color:rgb(255,255,255)"><font color="#00ff00">Here for FULL</font><font color="#00ff00">&nbsp;</font></span></font></b></a><font color="#00ff00" size="5"><a href="https://charwill.github.io" style="background-color:rgb(182,215,168)">https://charwill.github.io</a></font><a name="publications" style="background-color:transparent"><b><font size="5">]</font></b></a></h3>
<div align="justify">
<ul>




<li><a href="http://...">&nbsp;Quality Assessment of Screen Content Images Using Local-Global Feature Similarity</a>&nbsp; [<a href="https://drive.google.com/open?id=1zI_0BdG6Rztshu9CDgRuNJY-PKnGofca"><b><font color="#ff0000">implementation</font></b></a>], &nbsp;<br>
<b>Miaohui Wang</b>, <i>et al</i>.</li>



<li><b style="color:rgb(255,0,0);font-size:medium"><span style="background-color:transparent;text-align:left">New!!!&nbsp;</span></b><a href="http://.../">Rate Constrained Multiple-QP optimization for High Efficiency Video Coding</a>,&nbsp;<br>
<b>Miaohui Wang</b>, J. Xiong, L. Xu, W. Xie, K. N. Ngan and J. Qin- IEEE Transactions on Multimedia (<b>T-MM</b>)(doi  10.1109/TMM.2019.2947351), pp. 1-12, 2019.</li>



<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font>&nbsp;MSMC-Net: Image Inpainting using Deep Multi-scale and Multi-connection Networks, ICME 2019 Grand Challenges"[<b style="background-color:transparent;text-align:left"><font color="#ff0000">Second Runner-up</font></b><span style="background-color:transparent;text-align:left">][<a href="https://drive.google.com/file/d/1EDATio7EaSrre_axHbWWgBDe_EOrzPd7/view?usp=sharing"><b><font color="#ff0000">implementation</font></b></a>]</span><br>
<b>Miaohui Wang</b>, X. Chen, W. Chen, Y. Yuan, pp. 1-4, IEEE International Conference on Multimedia and Expo (<b>ICME</b>) 2019.
</li>


<li><b style="color:rgb(255,0,0);font-size:medium"><span style="background-color:transparent;text-align:left">New!!!&nbsp;</span></b><a href="http://.../">UHD Video Coding: A Light-weight Learning-based Fast Super-block Approach</a>,&nbsp;<br>
<b>Miaohui Wang</b>, W. Xie, X. Meng, H. Zeng and K. N. Ngan- IEEE Transactions on Circuits and Systems for Video Technology (<b>T-CSVT</b>)(doi  10.1109/TCSVT.2018.2873910), pp. 1-12.</li>


<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font>&nbsp;<a href="http://cvpr2019.thecvf.com/" rel="nofollow">Surface Reconstruction from Normals: A Robust DGP-based Discontinuity Preservation Approach</a>,&nbsp;<br>
W. Xie,&nbsp;<b>Miaohui Wang*</b>, J. Qin, M. Wei, and J. Jiang- IEEE Computer Society Conference on Computer Vision and Pattern Recognition (<b>CVPR</b> 2019).
</li>


<li><font color="#ff0000" size="3"><b><span style="background-color:transparent;text-align:left">New!!!</span></b></font>&nbsp;<a href="https://www.journals.elsevier.com/signal-processing-image-communication" rel="nofollow">Image Super-resolution via Feature-augmented Random Forest</a>&nbsp; [<a href="https://github.com/HarleyHK/FARF" rel="nofollow"><b><font color="#ff0000">implementation</font></b></a>],&nbsp;<br>
H. Li, K. M. Lam, and&nbsp;<b>Miaohui Wang</b>- Elsevier Signal Processing: Image Communication (<b>SPIC</b>)&nbsp;, 72, pp. 25-34, 2019.</span></li>

</ul>
</div>


  
 
<hr align="center" size="2" width="100%">
<a href="https://clustrmaps.com/site/prir" title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=DphxV4yLQeZrv3USGPJ3SslfkdDjn_Z8zWfPqGsqDlA"></a>
<div align="center" style="text-align:center">
<div align="center" style="text-align:center">
<p>
<span>Last Update: 2019. </span>
<span>WANG MIAOHUI </span>
<span>All rights reserved.</span>
</p>
</div>

</body>
</html>
